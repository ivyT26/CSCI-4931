{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np #for statistics and linear algebra computation\n",
    "import pandas as pd #for data processing and reading in data\n",
    "import matplotlib.pyplot as plt #for plotting data  and visuals\n",
    "import seaborn as sb #for more visualizations\n",
    "\n",
    "from scipy import stats #statistical tools\n",
    "from sklearn.model_selection import train_test_split #splitting data into training and test sets\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.metrics import classification_report #for computing confusion matrix\n",
    "\n",
    "#import keras library to implement neural networks\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "#import optimizers to train data\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.metrics import binary_crossentropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"dataset.csv\")#read dataset into variable\n",
    "# data.head(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(20,20))\n",
    "#sb.scatterplot(x='Balance', y='Exited', data=data) #display scatter plot to help visualize relationship b/w inputs and output\n",
    "#sb.scatterplot(x='EstimatedSalary', y='Exited', data=data)\n",
    "#sb.barplot(x='Age', y='Exited', data=data) #display bar graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sb.distplot(data['Tenure']) #display distribution plot\n",
    "#sb.distplot(data['EstimatedSalary'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation = data.corr() #find correlation in data\n",
    "plt.figure(figsize=(10,10))\n",
    "sb.heatmap(correlation)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x = data.drop('CustomerId', axis=1)\n",
    "x = x.drop('HasCrCard', axis=1)\n",
    "x = x.drop('EstimatedSalary', axis=1)\n",
    "x = x.drop('Surname', axis=1)\n",
    "x = x.drop('Balance', axis=1)\n",
    "x = x.drop('Exited', axis=1) #drop output variable you want to find from x data\n",
    "\n",
    "# print(x.shape) #obtains shape of data (this one is 9000 x 8)\n",
    "# print(x.columns) #obtains the names of the columns\n",
    "# print(x.Geography) #obtains the values that correspond to the column\n",
    "# print(x['Geography', 'Age']) #same aslast line but different format and can get multiple columns\n",
    "# print(x.loc[15]) #obtains a specific row\n",
    "# print(x.loc[0:2]) #obtains multiple rows\n",
    "# print(x[['Age', 'Gender']].loc[[1,3]]) #obtains specific rows and specific columns\n",
    "\n",
    "#convert geography values to int values\n",
    "#1 = Spain, 2 = France, 3 = Germany\n",
    "x['Geography'] = x['Geography'].replace(['Spain', 'France', 'Germany'], [1, 2, 3]) #replace a value with a new value\n",
    "        \n",
    "#convert gender values to int values\n",
    "#Female = 0, Male = 1\n",
    "x['Gender'] = x['Gender'].replace(['Female', 'Male'], [0, 1])\n",
    "\n",
    "x #get input values that have a correlation with target output 'Exited'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data['Exited']\n",
    "y #separate output values from dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split dataset into training and testing set (80-20 split)\n",
    "xTrain, xTest, yTrain, yTest = train_test_split(x, y, test_size=0.2, random_state=57) #set random state to an integer for identical splits\n",
    "# xTrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#need to scale data so that there aren't any outrageous values or distortions because of varying ranges of values\n",
    "scale = MinMaxScaler()\n",
    "#scale training samples\n",
    "xTrain_scaled = scale.fit_transform(xTrain)\n",
    "xTest_scaled = scale.fit_transform(xTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create ANN model here\n",
    "#ANN model 1\n",
    "ANN1 = keras.Sequential([\n",
    "    keras.Input(shape=7), #add input layer here\n",
    "    layers.Dense(11, name=\"layer1\"), #at this point it should have the weighted sum of the values from the input layer\n",
    "    layers.Dense(10, activation=\"relu\", name=\"layer2\"), #apply activation function\n",
    "    layers.Dense(5, activation=\"relu\", name=\"layer3\"),\n",
    "    layers.Dense(4, activation=\"relu\", name=\"layer4\"),\n",
    "    layers.Dense(1, activation=\"sigmoid\", name=\"layer5\")\n",
    "    \n",
    "])\n",
    "print(len(ANN1.layers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ANN1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#design F1-score function \n",
    "#F1-score = 2pr/(p+r)\n",
    "#https://keras.io/guides/writing_your_own_callbacks/, reference site\n",
    "class callbackValues(keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs=None): #epoch level method called at end of each epoch\n",
    "        keys = list(logs.keys()) #obtain what metrics were calculated and obtained each epoch\n",
    "        #print(\"Info obtained at end of epoch \", keys)\n",
    "        #here calculate the f1-score and print it out\n",
    "        train_precision = logs[keys[2]]\n",
    "        test_precision = logs[keys[6]]\n",
    "        train_recall = logs[keys[3]]\n",
    "        test_recall = logs[keys[7]]\n",
    "        train_denom = train_precision + train_recall #calculate f1 score for training data at each epoch\n",
    "        test_denom = test_precision + test_recall #calculate f1 score for test data at each epoch\n",
    "        #below is an error check to prevent division by zero\n",
    "        if (train_denom <= 0.0):\n",
    "            train_denom = 1\n",
    "        if (test_denom <= 0.0):\n",
    "            test_denom = 1\n",
    "        \n",
    "        train_f1 = 2 * train_precision * train_recall / (train_denom)\n",
    "        test_f1 = 2 * test_precision * test_recall / (test_denom)\n",
    "        print(\"Training F1 score: \", train_f1)\n",
    "        print(\"Validation F1 score: \", test_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train the model with the training dataset and validate with test dataset for accuracy, precision, recall, and F1-score parameters\n",
    "metrics=['accuracy', keras.metrics.Precision(), keras.metrics.Recall()]\n",
    "ANN1.compile(optimizer=Adam(learning_rate=0.0001), loss='binary_crossentropy', metrics=metrics)\n",
    "ANN1.fit(x=xTrain_scaled, y=yTrain, validation_data=(xTest_scaled, yTest), batch_size=55, epochs=100, shuffle=False,verbose=2, callbacks=[callbackValues()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#evaluate model with test dataset (do not need since it is validated in the fit function by adding validation data parameter to it, but below is an alternative)\n",
    "#results = ANN1.evaluate(xTest_scaled, yTest, batch_size=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ANN model 2\n",
    "ANN2 = keras.Sequential([\n",
    "    keras.Input(shape=7), #add input layer here\n",
    "    layers.Dense(11, name=\"layer1\"), #at this point it should have the weighted sum of the values from the input layer\n",
    "    layers.Dense(11, activation=\"relu\", name=\"layer2\"), #apply activation function\n",
    "    layers.Dense(9, activation=\"relu\", name=\"layer3\"),\n",
    "    layers.Dense(5, activation=\"relu\", name=\"layer4\"),\n",
    "    layers.Dense(3, activation=\"sigmoid\", name=\"layer5\"),\n",
    "    layers.Dense(1, activation=\"sigmoid\", name=\"layer6\")\n",
    "])\n",
    "ANN2.summary() #print summary of ANN2 structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train and validate model for ANN 2\n",
    "metrics=['accuracy', keras.metrics.Precision(), keras.metrics.Recall()]\n",
    "ANN2.compile(optimizer=Adam(learning_rate=0.0001), loss='binary_crossentropy', metrics=metrics)\n",
    "ANN2.fit(x=xTrain_scaled, y=yTrain, validation_data=(xTest_scaled, yTest), batch_size=100, epochs=100000, shuffle=False,verbose=2, callbacks=[callbackValues()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ANN model 3\n",
    "ANN3 = keras.Sequential([\n",
    "    keras.Input(shape=7), #add input layer here\n",
    "    layers.Dense(15, name=\"layer1\"), #at this point it should have the weighted sum of the values from the input layer\n",
    "    layers.Dense(20, activation=\"relu\", name=\"layer2\"), #apply activation function\n",
    "    layers.Dense(10, activation=\"relu\", name=\"layer3\"),\n",
    "    layers.Dense(5, activation=\"relu\", name=\"layer4\"),\n",
    "    layers.Dense(2, activation=\"relu\", name=\"layer5\"),\n",
    "    layers.Dense(1, activation=\"sigmoid\", name=\"layer6\")\n",
    "])\n",
    "ANN3.summary() #print summary of ANN3 structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train and validate model for ANN 3\n",
    "metrics=['accuracy', keras.metrics.Precision(), keras.metrics.Recall()]\n",
    "ANN3.compile(optimizer=Adam(learning_rate=0.0001), loss='binary_crossentropy', metrics=metrics)\n",
    "ANN3.fit(x=xTrain_scaled, y=yTrain, validation_data=(xTest_scaled, yTest), batch_size=150, epochs=1100, shuffle=False,verbose=2, callbacks=[callbackValues()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ANN model 4\n",
    "ANN4 = keras.Sequential([\n",
    "    keras.Input(shape=7), #add input layer here\n",
    "    layers.Dense(14, name=\"layer1\"), #at this point it should have the weighted sum of the values from the input layer\n",
    "    layers.Dense(7, activation=\"relu\", name=\"layer2\"), #apply activation function\n",
    "    layers.Dense(3, activation=\"relu\", name=\"layer3\"),\n",
    "    layers.Dense(1, activation=\"sigmoid\", name=\"layer4\"),\n",
    "])\n",
    "ANN4.summary() #print summary of ANN3 structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train and validate model for ANN 4\n",
    "metrics=['accuracy', keras.metrics.Precision(), keras.metrics.Recall()]\n",
    "ANN4.compile(optimizer=Adam(learning_rate=0.0001), loss='binary_crossentropy', metrics=metrics)\n",
    "ANN4.fit(x=xTrain_scaled, y=yTrain, validation_data=(xTest_scaled, yTest), batch_size=300, epochs=1000, shuffle=False,verbose=2, callbacks=[callbackValues()])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
